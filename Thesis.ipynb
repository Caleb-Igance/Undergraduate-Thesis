{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage import measure\n",
    "from scipy import interpolate\n",
    "from numpy import fft\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from pandas import read_csv, DataFrame\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/calebignace/etsu-thesis-s17/TrainingSet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Transform:\n",
    "    #points = np.array([]) # (x,y) points\n",
    "    def __init__(self, curve):\n",
    "                # complex representation:\n",
    "        complex_curve = curve[0] + 1j*curve[1] \n",
    "        self.transform = np.abs(fft.fft(complex_curve))\n",
    "    \n",
    "    def Plot():\n",
    "        plt.plot(self.transform)\n",
    "        plt.yscale('log')\n",
    "        plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Contour:\n",
    "    #(x,y) points\n",
    "    #Area enclosed by the points\n",
    "    def __init__(self, curve, points):\n",
    "        self.contour = self.Interpolate(curve, points)\n",
    "        self.centroid = [np.average(self.contour[0]), np.average(self.contour[1])]\n",
    "        self.area = self.Area()\n",
    "    \n",
    "    # Use Green's theorem to compute the area \n",
    "    # enclosed by the given contour.\n",
    "    def Area(self):\n",
    "        # vs - vertices/points on closed curve                                                                  \n",
    "        a = 0\n",
    "        x0, y0 = self.contour[0][0], self.contour[1][0]\n",
    "        #for [x1, y1] in vs[1:]:\n",
    "        for i in range(1,len(self.contour[0])):\n",
    "            xi = self.contour[0][i]\n",
    "            yi = self.contour[1][i]\n",
    "            dx = xi - x0\n",
    "            dy = yi - y0\n",
    "            a += 0.5*(y0*dx - x0*dy)\n",
    "            x0 = xi\n",
    "            y0 = yi\n",
    "        return a\n",
    "    \n",
    "    def Interpolate(self,curve, points):\n",
    "        x = curve[:,1]\n",
    "        y = curve[:,0]\n",
    "        tck, u = interpolate.splprep([x, y], s=0)\n",
    "        unew = np.arange(0, 1.0001, 1.0001/points)\n",
    "        return interpolate.splev(unew, tck)\n",
    "    \n",
    "    def Plot(self):\n",
    "        plt.plot(self.contour[0],self.contour[1])\n",
    "        plt.plot(self.centroid[0], self.centroid[1], 'b*', markersize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Character:\n",
    "    \"\"\"\n",
    "    image_path               - File path to image\n",
    "    image                    - The actual image\n",
    "    original_image_contours  - A list of Contour objects that we found in the image\n",
    "    original_areas\n",
    "    reduced_image_contours   - A list of Contour objects that met requirements\n",
    "    reduced_areas\n",
    "    image_transforms         - A list of the reduced_image_contours's Transform objects\n",
    "    classification           - What we have classified this object's respective image as\n",
    "    \"\"\"\n",
    "    def __init__(self, image_path, classification = None):\n",
    "        self.classification = classification\n",
    "        self.image_path = image_path\n",
    "        self.image = plt.imread(self.image_path)\n",
    "        self.original_contours = [Contour(contour, points = 2**8) for contour in \n",
    "            measure.find_contours(self.image, level = 0.5, fully_connected = 'high')]\n",
    "        self.original_areas = [contour.area for contour in self.original_contours]\n",
    "        self.largest_area = np.max(np.abs(self.original_areas))\n",
    "        self.reduced_contours, self.reduced_areas = self.RemoveInsignificantContours()\n",
    "        self.largest_area_index = self.reduced_areas.index(self.largest_area)\n",
    "        self.transforms = [Transform(contour.contour) for contour in self.reduced_contours]\n",
    "        self.centroids = [contour.centroid for contour in self.reduced_contours]\n",
    "        self.ordinals = self.Ordinals()\n",
    "        \n",
    "    def Ordinals(self):\n",
    "        epsilon = 1\n",
    "        ordinals = [[0, 0] for i in self.reduced_contours]\n",
    "        for i in range(len(self.reduced_contours)):\n",
    "            for j in range(len(self.reduced_contours)):\n",
    "                if i != j:\n",
    "                    print(type())\n",
    "                    centroid1 = self.reduced_contours[i].centroid\n",
    "                    centroid2 = self.reduced_contours[j].centroid\n",
    "                    print(centroid1)\n",
    "                    print(centroid2)\n",
    "                    if centroid1[0] > centroid2[0] + epsilon:\n",
    "                        ordinals[i][0] += 1\n",
    "                        print(1)\n",
    "                    if centroid1[1] > centroid2[1] + epsilon:\n",
    "                        ordinals[i][1] += 1\n",
    "                        print(2)\n",
    "                input()\n",
    "        return ordinals\n",
    "                    \n",
    "        \n",
    "    def in_hull(p, hull):\n",
    "        \"\"\"\n",
    "        Test if points in `p` are in `hull`\n",
    "\n",
    "        `p` should be a `NxK` coordinates of `N` points in `K` dimensions\n",
    "        `hull` is either a scipy.spatial.Delaunay object or the `MxK` array of the \n",
    "        coordinates of `M` points in `K`dimensions for which Delaunay triangulation\n",
    "        will be computed\n",
    "        \"\"\"\n",
    "        from scipy.spatial import Delaunay\n",
    "        if not isinstance(hull,Delaunay):\n",
    "            hull = Delaunay(hull)\n",
    "\n",
    "        return hull.find_simplex(p)>=0\n",
    "        \n",
    "    def RemoveInsignificantContours(self):\n",
    "        contours_copy = self.original_contours.copy()\n",
    "        contours_to_delete = []\n",
    "        j = 0\n",
    "        while j < len(contours_copy):\n",
    "            if np.abs(contours_copy[j].area) < 0.10*self.largest_area: \n",
    "                del contours_copy[j]\n",
    "            else: j += 1    \n",
    "        return [contours_copy, [contour.area for contour in contours_copy]]\n",
    "    \n",
    "    def PlotImage(self):\n",
    "        plt.imshow(self.image, cmap = 'gray')\n",
    "    \n",
    "    def PlotOriginalContours(self):\n",
    "        for contour in self.original_contours:\n",
    "            contour.Plot()\n",
    "        plt.axis('equal')\n",
    "    \n",
    "    def PlotReducedContours(self):\n",
    "        for contour in self.reduced_contours:\n",
    "            contour.Plot()\n",
    "        plt.axis('equal')\n",
    "            \n",
    "    def PlotImageAndOriginalContours(self):\n",
    "        self.PlotImage()\n",
    "        self.PlotOriginalContours()\n",
    "    \n",
    "    def PlotImageAndReducedContours(self):\n",
    "        self.PlotImage()\n",
    "        self.PlotReducedContours()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GenerateClassifications(N):\n",
    "    digits = ['0','1','2','3','4','5','6','7','8','9']\n",
    "    digits = list(np.sort(N*digits))\n",
    "    lower_letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "    lower_letters = list(np.sort(N*lower_letters))\n",
    "    upper_letters = [char.upper() for char in lower_letters]\n",
    "    return digits + upper_letters + lower_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetImagePaths(folder_path, M, N):\n",
    "    image_paths = []\n",
    "    for i in range(0, 62):\n",
    "        if i < 10:\n",
    "            si = '0'+str(i)\n",
    "        else:\n",
    "            si = str(i)\n",
    "        for j in range(M, M+N):\n",
    "            image_paths.append(folder_path+si+'/'+si+'-'+(5 - len(str(j)))*'0'+str(j)+'.png')\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CreateDataSet(M, N, folder_path = '/Users/calebignace/etsu-thesis-s17/TrainingSet/'):\n",
    "    \"\"\"\n",
    "    Caleb Ignace\n",
    "    Febuary 1, 2017\n",
    "    \n",
    "    | Inputs:\n",
    "    =====================\n",
    "    *folder_path      *M - start at image M      *N - include N images\n",
    "    \n",
    "    | Outputs:\n",
    "    =====================\n",
    "    *dataset - A list of Character objects.\n",
    "    \n",
    "    \n",
    "    | Notes:\n",
    "    =====================\n",
    "    Refering to the file structure of the data set in the folder TrainingSet:\n",
    "        A directory below TrainingSet are folders for each character (0,1,...,9,A,B,...,Z,a,b,...,z), labeled \n",
    "        00,01,...,61. For images of the digit \"0\" (zero), the paths will be \n",
    "        \"TrainingSet/00/00-00001.png\",\n",
    "        \"TrainingSet/00/00-00002.png\",\n",
    "                    ...\n",
    "        \"TrainingSet/00/00-00100.png\".\n",
    "        The other folders 01 through 61 follow the same structure.\n",
    "    The images of each character that are includes are M,M+1,...,M+N-1.\n",
    "    (1) If N = 2, then image_classifications = ['0', '0', '1', '1', ... , 'z', 'z'] and its length is 62*N = 124.\n",
    "    (2) A list of Strings that contain the file path of each image in data set.\n",
    "    \"\"\"\n",
    "    #image_classifications = GenerateClassifications(N)                  # (1)\n",
    "    image_paths = GetImagePaths(folder_path, M, N)                       # (2)\n",
    "    dataset = [Character(image_path) for image_path in image_paths]             \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TransformsInASingleList(transforms_arrays): # 124 enteries of 256 points\n",
    "    #print(transforms_arrays)\n",
    "    transforms = np.zeros( (len(transforms_arrays[0]),len(transforms_arrays)) )\n",
    "    #print(transforms.shape)\n",
    "    for i in range(len(transforms_arrays)):\n",
    "        #print(len(transforms[:,i]))\n",
    "        #print(len(transforms_arrays[i]))\n",
    "        a =  transforms_arrays[i]\n",
    "        transforms[:,i] = a\n",
    "        #input()\n",
    "        #break\n",
    "    return transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k_neighbors):\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.kNN = KNeighborsClassifier(n_neighbors = self.k_neighbors, metric='euclidean')\n",
    "        \n",
    "    def Fit(self, data_train, N_train):\n",
    "        self.data_train = data_train\n",
    "        self.N_train = N_train\n",
    "        self.kNN.fit(self.data_train.T, self.data_train.columns)\n",
    "        #self.distances, self.neighbors = self.kNN.kneighbors(data_train.T)\n",
    "        \n",
    "    def Predict(self, data_test, N_test, image_classifications_test):\n",
    "        self.N_test = N_test\n",
    "        \n",
    "        predictions = self.kNN.predict(data_test.T)\n",
    "        \n",
    "        accuracies = []\n",
    "        result = 'Symbol   Accuracy   Predictioned as'\n",
    "\n",
    "        truth = predictions == image_classifications_test\n",
    "\n",
    "        digits = ['0','1','2','3','4','5','6','7','8','9']\n",
    "        lower_letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "        upper_letters = [char.upper() for char in lower_letters]\n",
    "        symbols = digits + upper_letters + lower_letters\n",
    "        \n",
    "        for i in range(62):\n",
    "            f = i*N_test\n",
    "            l = (i+1)*self.N_test\n",
    "            accuracies.append(np.sum([1 for p in truth[f:l] if p])/N_test)\n",
    "            result += \"\\n\" + str(symbols[i]) + \"        \" + '{0:.3f}'.format(float(round(accuracies[i], 3))) + \"      \" + str(''.join(predictions[f:l]))      \n",
    "            \n",
    "        accuracy = np.sum(accuracies)/len(accuracies)\n",
    "        \n",
    "        predictions_upper = [p.upper() for p in predictions]\n",
    "        image_classifications_test_upper = [c.upper() for c in image_classifications_test]\n",
    "\n",
    "        truth = [predictions_upper[i] == image_classifications_test_upper[i] for i in range(len(predictions_upper))]\n",
    "\n",
    "        real_accuracy = np.sum(truth)/len(truth)\n",
    "        \n",
    "        head = \"Accuracy: \" + str(accuracy) + \"\\nReal Accuracy: \" + str(real_accuracy) + \"       (example: 'W' is equivalent to 'w')\\n\"\n",
    "    \n",
    "        result = head + result\n",
    "        \n",
    "        return accuracy, real_accuracy, result\n",
    "    \n",
    "    def Plot(self, figuresize = (15,15), save = False, labels = True, vertex_size = 300, vertex_color = \"cyan\", font_size = 10):\n",
    "        # NOTE TO SELF: When I start to actually test agains real scene images, N_train will not longer apply at (1)\n",
    "        kNNadjacencies = self.kNN.kneighbors_graph()     \n",
    "        kNNgraph = nx.Graph( kNNadjacencies )\n",
    "        nx.relabel_nodes(kNNgraph, dict(zip(range(62*self.N_train),self.data_train.columns)), copy=False ) # (1)\n",
    "        plt.figure(figsize = figuresize)\n",
    "        nx.draw(kNNgraph, node_color = vertex_color, with_labels = labels, node_size = vertex_size)\n",
    "        plt.title('nodes labeled classification', fontsize = font_size)\n",
    "        if save: plt.savefig(\"graph.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RunKNN(k_neighbors, M_train, N_train, M_test, N_test):\n",
    "    \n",
    "    training_set = CreateDataSet(M = M_train, N = N_train)\n",
    "    transforms_train = [character.transforms[character.largest_area_index] for character in training_set] \n",
    "    image_classifications_train = GenerateClassifications(N_train)\n",
    "    trans = [transform.transform for transform in transforms_train]\n",
    "    transforms_curves_train = TransformsInASingleList(trans)\n",
    "    transforms_train = DataFrame(transforms_curves_train, columns = image_classifications_train)\n",
    "    #transforms_train.head()\n",
    "    \n",
    "    testing_set = CreateDataSet(M = M_test, N = N_test)\n",
    "    transforms_test = [character.transforms[character.largest_area_index] for character in testing_set] \n",
    "    image_classifications_test = GenerateClassifications(N_test)\n",
    "    transforms_curves_test = TransformsInASingleList([transform.transform for transform in transforms_test])\n",
    "    transforms_test = DataFrame(transforms_curves_test, columns = image_classifications_test)\n",
    "    #transforms_test.head()\n",
    "    \n",
    "    #accuracies = [0]*number_runs\n",
    "    #real_accuracies = [0]*number_runs\n",
    "    #results = []\n",
    "    \n",
    "    #for run in range(number_runs):\n",
    "    kNN = KNN(k_neighbors)\n",
    "    kNN.Fit(transforms_train, N_train)\n",
    "    accuracy, real_accuracy, result = kNN.Predict(transforms_test, N_test, image_classifications_test)\n",
    "    \n",
    "    return accuracy, real_accuracy, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainig set: for every character, will start at file number **M_train** and take **N_train** files.\n",
    "\n",
    "Testing set: for every character, will start at file number **M_test (M_train + 1)** and take **N_test** files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy, real_accuracy, result = RunKNN(k_neighbors = 2, M_train = 1, N_train = 1, M_test = 1 + 1, N_test = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.50806451612903225, 0.62096774193548387)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy, real_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.508064516129\n",
      "Real Accuracy: 0.620967741935       (example: 'W' is equivalent to 'w')\n",
      "Symbol   Accuracy   Predictioned as\n",
      "0        1.000      00\n",
      "1        0.500      1I\n",
      "2        1.000      22\n",
      "3        1.000      33\n",
      "4        1.000      44\n",
      "5        0.000      22\n",
      "6        1.000      66\n",
      "7        1.000      77\n",
      "8        0.500      08\n",
      "9        1.000      99\n",
      "A        1.000      AA\n",
      "B        0.500      OB\n",
      "C        0.500      C3\n",
      "D        0.000      O0\n",
      "E        0.500      6E\n",
      "F        0.500      FE\n",
      "G        1.000      GG\n",
      "H        1.000      HH\n",
      "I        1.000      II\n",
      "J        0.000      99\n",
      "K        1.000      KK\n",
      "L        1.000      LL\n",
      "M        1.000      MM\n",
      "N        0.000      HH\n",
      "O        0.500      O0\n",
      "P        1.000      PP\n",
      "Q        0.500      QB\n",
      "R        1.000      RR\n",
      "S        1.000      SS\n",
      "T        0.000      PF\n",
      "U        0.000      nR\n",
      "V        1.000      VV\n",
      "W        0.500      MW\n",
      "X        1.000      XX\n",
      "Y        1.000      YY\n",
      "Z        1.000      ZZ\n",
      "a        1.000      aa\n",
      "b        1.000      bb\n",
      "c        0.000      aC\n",
      "d        1.000      dd\n",
      "e        0.000      a9\n",
      "f        0.500      fT\n",
      "g        0.000      99\n",
      "h        0.000      44\n",
      "i        1.000      ii\n",
      "j        0.000      ii\n",
      "k        0.000      b5\n",
      "l        0.000      II\n",
      "m        0.000      GG\n",
      "n        1.000      nn\n",
      "o        0.000      QO\n",
      "p        0.000      DP\n",
      "q        0.000      Qp\n",
      "r        0.000      77\n",
      "s        0.000      SS\n",
      "t        0.000      bL\n",
      "u        0.000      nn\n",
      "v        0.500      vV\n",
      "w        0.000      WW\n",
      "x        0.000      XX\n",
      "y        0.000      YY\n",
      "z        0.000      8Z\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ManyRuns(rangeK, M_train, N_train, M_test, N_test):\n",
    "    \n",
    "    print(\"Building data sets\")\n",
    "    \n",
    "    training_set = CreateDataSet(M = M_train, N = N_train)\n",
    "    transforms_train = [character.transforms[character.largest_area_index] for character in training_set] \n",
    "    image_classifications_train = GenerateClassifications(N_train)\n",
    "    trans = [transform.transform for transform in transforms_train]\n",
    "    transforms_curves_train = TransformsInASingleList(trans)\n",
    "    transforms_train = DataFrame(transforms_curves_train, columns = image_classifications_train)\n",
    "    #transforms_train.head()\n",
    "    \n",
    "    testing_set = CreateDataSet(M = M_test, N = N_test)\n",
    "    transforms_test = [character.transforms[character.largest_area_index] for character in testing_set] \n",
    "    image_classifications_test = GenerateClassifications(N_test)\n",
    "    transforms_curves_test = TransformsInASingleList([transform.transform for transform in transforms_test])\n",
    "    transforms_test = DataFrame(transforms_curves_test, columns = image_classifications_test)\n",
    "    \n",
    "    accuracies = [0]*len(rangeK)\n",
    "    real_accuracies = [0]*len(rangeK)\n",
    "    results = []\n",
    "    \n",
    "    for i in range(len(rangeK)):\n",
    "        print(\"Running on k = \"+str(rangeK[i]))\n",
    "        kNN = KNN(rangeK[i])\n",
    "        kNN.Fit(transforms_train, N_train)\n",
    "        accuracies[i], real_accuracies[i], result = RunKNN(rangeK[i], M_train, N_train, M_test, N_test)\n",
    "        results.append(result)\n",
    "        \n",
    "    return accuracies, real_accuracies, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building data sets\n"
     ]
    }
   ],
   "source": [
    "rangeK = [1,2,3]#list(range(1,10)) # Note k cannot be creater than 62*N_train\n",
    "accuracies, real_accuracies, results = ManyRuns(rangeK, M_train = 1, N_train = 900, M_test = 901, N_test = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.826451612903\n",
      "Real Accuracy: 0.871935483871       (example: 'W' is equivalent to 'w')\n",
      "Symbol   Accuracy   Predictioned as\n",
      "0        0.680      000000000000oo00o00O0O000000oo0000Oo000oo00000o00oOO00000000O0O0O0O0O0O0O0O000000000Q0ooX8QX0000O00O\n",
      "1        0.820      11111111111111rr111111111111bb111111111111111111111111111111ll11ll11ll11ll11111111111q71yyQV11111111\n",
      "2        0.950      22222222222222222222222222222g22222222222222222222222222sS222222222222222222222222225522222222222222\n",
      "3        0.920      3333333333333333333333333333trlF33333333333333333333333333333333333333333333333333333333SSVV33333333\n",
      "4        0.920      444444444444hhWW444444444444444444444444444444444444444444444444444444444444444444444b444uzA44444444\n",
      "5        0.890      5555555555555555555555555555gggg555S55555555555555555555555555555555555555555555555s5S5533VV55555555\n",
      "6        0.830      6666666666666666666966666666996666669666666666666666666666669666966696669666696666661bp7VVQN66666666\n",
      "7        0.920      7777777777777777777777777777777777777777777777777777777777777777777777777777777777771111SmCC77777777\n",
      "8        0.930      88888888888888888888888888888888888888888888888888888888888888888888888888888888888866668NNN88888888\n",
      "9        0.880      9999999999999999999999999999bp669999999999999999999999999999999999999999999999999999mm5zNNXz99999999\n",
      "A        0.850      AAAAAAAaAAAAkkkkAAAAAAAAAAAAddddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAvvAANNzQAAAAAAAA\n",
      "B        0.830      BBBBBBBBBBBBLLssBB8BBBBBBBBBhhhhBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBFFF8TJMVBBBBBBBB\n",
      "C        0.720      CcCcCCccCCCcccCCCcCCCCCCCCcCeeeCCcCcCCCCCcCcCCCCCCCCCcCcCCCCCcCCCcCCCcCCCcCCCcCcCCCCCCCCVmNNCCCCCCCC\n",
      "D        0.840      DDDDDDDDDDDD99ssDDDDDDDDDDDDeebbDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDeqeqOSyVDDDDDDDD\n",
      "E        0.880      EEEEEEEEEEEECCCCEEEEEEEEEEEE3339EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEmmEEEEVVEEEEEEEE\n",
      "F        0.870      FFFFFFFFFFFFWWVVFFFFFFFFFFFFLLffFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFfFFFCGVVFFFFFFFF\n",
      "G        0.810      GcGcGGCcGGGGccccGGGGGGGGGGGGGnu2GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGccvkVmNNGGGGGGGG\n",
      "H        0.890      HHHHHHHHHHHHqqkkHHHHHHHHHHHHz2zhHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHxMWHHHHHHHH\n",
      "I        0.850      IIIIIIIIIIIl99ccIIIIIIIIIIIIL9LgIIIIIIIIIIIIIIIIIIIIIIIIIkllIIIIIIIIIIIIIIIIIIIIIIIIIJIIIIyyIIIIIIII\n",
      "J        0.840      JJJJJJJJJJJJvvVVJJJJJJJJJJJJJJLJCclJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJ77llKKyyJJJJJJJJ\n",
      "K        0.890      KKKKKKKKKKKKzzHHKKKKKKKKKKKKHpKfKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKUUQQKKKKKKKK\n",
      "L        0.840      LLLLLLLLLLLLAAAALlLLLLLLLLLLihhhLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLL11JLJ622LLLLLLLL\n",
      "M        0.790      MWMWMWMWMMMMmmmmMMmMMMMMMMMMFFw3MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMKAuHVI33MMMMMMMM\n",
      "N        0.920      NNNNNNNNNNNNNNNNNNNNNNNNNNNNMgggNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNIIyyNNNNNNNN\n",
      "O        0.450      O0O0O00OOOoo99LLOO0ooOoOOoOOGGceooOooOOooooOOOOOOOOOoOoOOoOO0000O0000000O000OOOoOoOoQogomXNNOOOOOOOO\n",
      "P        0.860      PPPPPPPPPPPPPPssPPPPPPPPPPPPnun4PPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPbopbtFNMPPPPPPPP\n",
      "Q        0.850      QQQQQQQQQQQQ22RRQQQQQQQQQQQQBGGGQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQ1qbQX8NNQQQQQQQQ\n",
      "R        0.850      RRRRRRRRRRRRyyaaRRRRRRRRRRRRrr44RRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRt1tRtwVZRRRRRRRR\n",
      "S        0.700      SsSsSsSsSSSS3333SSzZSSSSSSSSIIIISsSsSsSsSSSsSSSSSSSSSSSSsSSSSSSSSSSSSSSSSSSSSSSSSsssSs5s88VVSSSSSSSS\n",
      "T        0.890      TTTTTTTTTTTTPPTTTTTTTTTTTTTT77VVTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTppTTT9mmTTTTTTTT\n",
      "U        0.850      UUUUUUUUUUUURRvvUuUUUUUUUUUUUUMgUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUhhnnTDQyUUUUUUUU\n",
      "V        0.740      VVVVVVVvVVVVvvvvVvvvVvVvVVVVlqvvVvVvVVVVVVvVVvVvVVVVVVvVVVVVVVVVVVVVVVVVVVVVVVVvVVVVVVvVyyXQVVVVVVVV\n",
      "W        0.730      WWWWWWWWWWWWwwwwWWWWWwWWwwwwzzmwWWwWWWWWWwWWWWWWWWWWWWWWWWWWWWWwWWWwWWWwWWWwWWWWWMWMmwWWy8XXWWWWWWWW\n",
      "X        0.760      XXXXXXxXXXXXxxxxXXXxXxXXXXXXkkAkXXXXXXXXXxXxXXXXXXXXXXXXXxXxXXXXXXXXXXXXXXXXXXxXXXXXkk11QQQNXXXXXXXX\n",
      "Y        0.860      YYYYYYYYYYYYhhyyYYYYYYYYYYYYYYyrYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYyyyyMMQVYYYYYYYY\n",
      "Z        0.730      ZZZZZZZZZZZZWWttZzZZZZZZZZZZNNNxzzzZZzZzZzZzZZZZZZZZZZzZZZZZZZZZZZZZZZZZZZZZZZZZZzZz2222Sm22ZZZZZZZZ\n",
      "a        0.880      aaaaaaaaaaaa44aaaaagaaaaaaaaaaaQaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaahAhAYYNNaaaaaaaa\n",
      "b        0.870      bbbbbbbbbbbbbbIIbbbbbbbbbbbbqqb4bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbLIl9IUyQbbbbbbbb\n",
      "c        0.610      ccccccccccccbbhhCcCCCccCcccceeeCCCCCcCccccccccCcccccCcCcccCcCCccCCccCCccCCcccccccCcceeneX8NNcccccccc\n",
      "d        0.930      ddddddddddddAAddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddAdddUUQVdddddddd\n",
      "e        0.870      eeeeeeeeeeeebbGGeeeeeeeeeeeeeee9eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeqqLQKUKKeeeeeeee\n",
      "f        0.870      ffffffffffffyyAAfffffffffffffffFffffffffffffffffffffffffffffffffffffffffffffffffffffkl99TnVVffffffff\n",
      "g        0.840      ggggggggggggppbbgggggggggggg9999ggggggggggggggggggggggggggggggggggggggggggggggggggggft11iiXXgggggggg\n",
      "h        0.890      hhhhhhhhhhhhkkhhhhhhhhhhhhhhhhhehhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhbmb6KUQQhhhhhhhh\n",
      "i        0.950      iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiijiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiAAXViiiiiiii\n",
      "j        0.910      jjjjjjjjjjjjiijjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjiijiLLQyjjjjjjjj\n",
      "k        0.880      kkkkkkkkkkkkkkkkkkkkkkkkkkkkuuaakkkkkRkRkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkknkhkKUzQkkkkkkkk\n",
      "l        0.820      l7l7llllllllLLLLllllllllllllQQ11lllllllllllllllllllllllllllllllllllllllllllll1lIllllJJlJlkyyllllllll\n",
      "m        0.910      mmmmmmmmmmmmttttmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmrmmmUU88mmmmmmmm\n",
      "n        0.800      nnnnnnnnnnunwwMMnnnnnnnnnnnnuuuunnnnnnnnnnuunnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnunnnnnWwwwVINNnnnnnnnn\n",
      "o        0.600      ooooooooooOoppqqoooOOoooooooooOOOO0O0ooOoOOoooooooooOoooooooOoOo0oOoOoOo0oOooOooOOOO4QbQX8NNooooOooo\n",
      "p        0.840      ppppppppppppWWhhpppPpppppppppprpppppppppppppppppppppppppppppppppppppppppppppppppppPPgfgtIIVVpppppppp\n",
      "q        0.840      qqqqqqqqqqqqKKKKqqqqqqqqqqqqbbVVqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqNzN1UYXXqqqqqqqq\n",
      "r        0.870      rrrrrrrrrrrrWWrrrrrrrrrrrrrr7rpPrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrHuuhIIQNrrrrrrrr\n",
      "s        0.690      ssssssssssssLLddssZZsSsSsssssSssssssssssssssssssssssssssSsSsSsSSSsSSSsSSSsSSssssssssuuhh888Vssssssss\n",
      "t        0.850      ttttttttttttqqxxttttttttttttoPPPttttttttttttttttttttttttttttttttttttttttttttttttttttk4tfKwVVtttttttt\n",
      "u        0.840      ununuunuuuuuuuuuuuuuuunuuuuunuuuuunuuuuuuuuuuuuuuuuuuunuuuuuuuuuuuuuuuuuuuuuuunuuuuuaWhWYYzzuuuuuuuu\n",
      "v        0.680      vvvvvvvvvvvv7711vvvvvVvvVvvvVvv7VvvvvvvvvvvVvvvvvvvvvvvvvvVvVVVVVvVVVVVVVvVVvvvvvvvvPevByyVVvvvvvvvv\n",
      "w        0.840      wwwwwwwwwwwwmmmmwwwwwWwWWwWwwwwwwwWwwwwwwWwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww4tww88yzwwwwwwww\n",
      "x        0.830      xXxXxxxxxxxxxxxxxxxxxxxxXxXxxxxXxxxxxxxxxXxXxxxxxxxxxxxxxXxXxxxxxxxxxxxxxxxxxxxxxxxxkkMMQQ8Qxxxxxxxx\n",
      "y        0.880      yyyyyyyyyyyyKKFFyyyYyyyyyyyyyPy7yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyzyyYzy88yyyyyyyy\n",
      "z        0.620      zzzzzzzzzzzzkkuuzzZZzzzzzzzznNHHzZzZzzzzzZzzzzzzzzzzzzZzzzzzZZZZZZZZZZZZZZZZzzzzzzzzgtygZZVVzzzzzzzz\n"
     ]
    }
   ],
   "source": [
    "print(results[0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
